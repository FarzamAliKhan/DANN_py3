{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Kaggle Environment\n",
    "Set up the Kaggle environment by installing necessary packages and configuring the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install torch torchvision\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Define constants\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "image_size = 28\n",
    "n_epoch = 100\n",
    "\n",
    "# Define paths for datasets and models\n",
    "source_dataset_name = 'MNIST'\n",
    "target_dataset_name = 'mnist_m'\n",
    "source_image_root = f'/kaggle/input/{source_dataset_name}'\n",
    "target_image_root = f'/kaggle/input/{target_dataset_name}'\n",
    "model_root = '/kaggle/working/models'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "import os\n",
    "os.makedirs(model_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including PyTorch, NumPy, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional necessary libraries\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import custom modules\n",
    "from data_loader import GetLoader\n",
    "from model import CNNModel\n",
    "from test import test\n",
    "from functions import ReverseLayerF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CNN Model\n",
    "Define the CNN model class as per the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN Model\n",
    "import torch.nn as nn\n",
    "from functions import ReverseLayerF\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.feature = nn.Sequential()\n",
    "        self.feature.add_module('f_conv1', nn.Conv2d(3, 64, kernel_size=5))\n",
    "        self.feature.add_module('f_bn1', nn.BatchNorm2d(64))\n",
    "        self.feature.add_module('f_pool1', nn.MaxPool2d(2))\n",
    "        self.feature.add_module('f_relu1', nn.ReLU(True))\n",
    "        self.feature.add_module('f_conv2', nn.Conv2d(64, 50, kernel_size=5))\n",
    "        self.feature.add_module('f_bn2', nn.BatchNorm2d(50))\n",
    "        self.feature.add_module('f_drop1', nn.Dropout2d())\n",
    "        self.feature.add_module('f_pool2', nn.MaxPool2d(2))\n",
    "        self.feature.add_module('f_relu2', nn.ReLU(True))\n",
    "        \n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(50 * 4 * 4, 100))\n",
    "        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_drop1', nn.Dropout())\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n",
    "        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(100, 10))\n",
    "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(50 * 4 * 4, 100))\n",
    "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n",
    "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, input_data, alpha):\n",
    "        input_data = input_data.expand(input_data.data.shape[0], 3, 28, 28)\n",
    "        feature = self.feature(input_data)\n",
    "        feature = feature.view(-1, 50 * 4 * 4)\n",
    "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "        class_output = self.class_classifier(feature)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "        \n",
    "        return class_output, domain_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Reverse Layer Function\n",
    "Define the ReverseLayerF function as per the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Reverse Layer Function\n",
    "from torch.autograd import Function\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Loader\n",
    "Define the data loader class to load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Loader\n",
    "class GetLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root, data_list, transform=None):\n",
    "        self.root = data_root\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(data_list, 'r') as f:\n",
    "            data_list = f.readlines()\n",
    "\n",
    "        self.n_data = len(data_list)\n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "\n",
    "        for data in data_list:\n",
    "            self.img_paths.append(data[:-3])\n",
    "            self.img_labels.append(data[-2])\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_paths, labels = self.img_paths[item], self.img_labels[item]\n",
    "        imgs = Image.open(os.path.join(self.root, img_paths)).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            imgs = self.transform(imgs)\n",
    "            labels = int(labels)\n",
    "\n",
    "        return imgs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training and Testing Functions\n",
    "Define the functions for training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training and Testing Functions\n",
    "\n",
    "def train(model, dataloader_source, dataloader_target, optimizer, loss_class, loss_domain, n_epoch, cuda):\n",
    "    best_accu_t = 0.0\n",
    "    for epoch in range(n_epoch):\n",
    "        len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
    "        data_source_iter = iter(dataloader_source)\n",
    "        data_target_iter = iter(dataloader_target)\n",
    "\n",
    "        for i in range(len_dataloader):\n",
    "            p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "            # Training model using source data\n",
    "            data_source = data_source_iter.next()\n",
    "            s_img, s_label = data_source\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_size = len(s_label)\n",
    "            domain_label = torch.zeros(batch_size).long()\n",
    "\n",
    "            if cuda:\n",
    "                s_img = s_img.cuda()\n",
    "                s_label = s_label.cuda()\n",
    "                domain_label = domain_label.cuda()\n",
    "\n",
    "            class_output, domain_output = model(input_data=s_img, alpha=alpha)\n",
    "            err_s_label = loss_class(class_output, s_label)\n",
    "            err_s_domain = loss_domain(domain_output, domain_label)\n",
    "\n",
    "            # Training model using target data\n",
    "            data_target = data_target_iter.next()\n",
    "            t_img, _ = data_target\n",
    "\n",
    "            batch_size = len(t_img)\n",
    "            domain_label = torch.ones(batch_size).long()\n",
    "\n",
    "            if cuda:\n",
    "                t_img = t_img.cuda()\n",
    "                domain_label = domain_label.cuda()\n",
    "\n",
    "            _, domain_output = model(input_data=t_img, alpha=alpha)\n",
    "            err_t_domain = loss_domain(domain_output, domain_label)\n",
    "            err = err_t_domain + err_s_domain + err_s_label\n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sys.stdout.write('\\r epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "                  % (epoch, i + 1, len_dataloader, err_s_label.data.cpu().numpy(),\n",
    "                     err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # Save model\n",
    "        torch.save(model, f'{model_root}/mnist_mnistm_model_epoch_current.pth')\n",
    "\n",
    "        # Test model\n",
    "        accu_s = test(source_dataset_name)\n",
    "        accu_t = test(target_dataset_name)\n",
    "        if accu_t > best_accu_t:\n",
    "            best_accu_s = accu_s\n",
    "            best_accu_t = accu_t\n",
    "            torch.save(model, f'{model_root}/mnist_mnistm_model_epoch_best.pth')\n",
    "\n",
    "    print('============ Summary ============= \\n')\n",
    "    print('Accuracy of the %s dataset: %f' % ('mnist', best_accu_s))\n",
    "    print('Accuracy of the %s dataset: %f' % ('mnist_m', best_accu_t))\n",
    "    print('Corresponding model was saved in ' + model_root + '/mnist_mnistm_model_epoch_best.pth')\n",
    "\n",
    "def test(dataset_name):\n",
    "    assert dataset_name in ['MNIST', 'mnist_m']\n",
    "    model_root = 'models'\n",
    "    image_root = os.path.join('dataset', dataset_name)\n",
    "    batch_size = 128\n",
    "    image_size = 28\n",
    "    alpha = 0\n",
    "\n",
    "    # Load data\n",
    "    img_transform_source = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "    ])\n",
    "    img_transform_target = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    if dataset_name == 'mnist_m':\n",
    "        test_list = os.path.join(image_root, 'mnist_m_test_labels.txt')\n",
    "        dataset = GetLoader(\n",
    "            data_root=os.path.join(image_root, 'mnist_m_test'),\n",
    "            data_list=test_list,\n",
    "            transform=img_transform_target\n",
    "        )\n",
    "    else:\n",
    "        dataset = datasets.MNIST(\n",
    "            root='dataset',\n",
    "            train=False,\n",
    "            transform=img_transform_source,\n",
    "        )\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "    # Test model\n",
    "    model = torch.load(os.path.join(model_root, 'mnist_mnistm_model_epoch_current.pth'))\n",
    "    model = model.eval()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    len_dataloader = len(dataloader)\n",
    "    data_target_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "    while i < len_dataloader:\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, t_label = data_target\n",
    "        batch_size = len(t_label)\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            t_label = t_label.cuda()\n",
    "        class_output, _ = model(input_data=t_img, alpha=alpha)\n",
    "        pred = class_output.data.max(1, keepdim=True)[1]\n",
    "        n_correct += pred.eq(t_label.data.view_as(pred)).cpu().sum()\n",
    "        n_total += batch_size\n",
    "        i += 1\n",
    "    accu = n_correct.data.numpy() * 1.0 / n_total\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Load the MNIST and mnist_m datasets and prepare data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "# Define image transformations for source and target datasets\n",
    "img_transform_source = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])\n",
    "\n",
    "img_transform_target = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load source dataset (MNIST)\n",
    "dataset_source = datasets.MNIST(\n",
    "    root='/kaggle/input/mnist',\n",
    "    train=True,\n",
    "    transform=img_transform_source,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "dataloader_source = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_source,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "# Load target dataset (mnist_m)\n",
    "train_list = os.path.join(target_image_root, 'mnist_m_train_labels.txt')\n",
    "\n",
    "dataset_target = GetLoader(\n",
    "    data_root=os.path.join(target_image_root, 'mnist_m_train'),\n",
    "    data_list=train_list,\n",
    "    transform=img_transform_target\n",
    ")\n",
    "\n",
    "dataloader_target = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_target,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model, Optimizer, and Loss Functions\n",
    "Initialize the CNN model, optimizer, and loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model, Optimizer, and Loss Functions\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = CNNModel()\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Define loss functions\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "# Move model and loss functions to GPU if available\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "    loss_class = loss_class.cuda()\n",
    "    loss_domain = loss_domain.cuda()\n",
    "\n",
    "# Ensure all model parameters are trainable\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Train the model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "# Train the model using the training data\n",
    "train(model, dataloader_source, dataloader_target, optimizer, loss_class, loss_domain, n_epoch, cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model\n",
    "Test the model using the test data and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "\n",
    "# Define the test function\n",
    "def test(dataset_name):\n",
    "    assert dataset_name in ['MNIST', 'mnist_m']\n",
    "    model_root = '/kaggle/working/models'\n",
    "    image_root = f'/kaggle/input/{dataset_name}'\n",
    "    batch_size = 128\n",
    "    image_size = 28\n",
    "    alpha = 0\n",
    "\n",
    "    # Load data\n",
    "    img_transform_source = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "    ])\n",
    "    img_transform_target = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    if dataset_name == 'mnist_m':\n",
    "        test_list = os.path.join(image_root, 'mnist_m_test_labels.txt')\n",
    "        dataset = GetLoader(\n",
    "            data_root=os.path.join(image_root, 'mnist_m_test'),\n",
    "            data_list=test_list,\n",
    "            transform=img_transform_target\n",
    "        )\n",
    "    else:\n",
    "        dataset = datasets.MNIST(\n",
    "            root='/kaggle/input/mnist',\n",
    "            train=False,\n",
    "            transform=img_transform_source,\n",
    "        )\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "    # Test model\n",
    "    model = torch.load(os.path.join(model_root, 'mnist_mnistm_model_epoch_current.pth'))\n",
    "    model = model.eval()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    len_dataloader = len(dataloader)\n",
    "    data_target_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "    while i < len_dataloader:\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, t_label = data_target\n",
    "        batch_size = len(t_label)\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            t_label = t_label.cuda()\n",
    "        class_output, _ = model(input_data=t_img, alpha=alpha)\n",
    "        pred = class_output.data.max(1, keepdim=True)[1]\n",
    "        n_correct += pred.eq(t_label.data.view_as(pred)).cpu().sum()\n",
    "        n_total += batch_size\n",
    "        i += 1\n",
    "    accu = n_correct.data.numpy() * 1.0 / n_total\n",
    "    return accu\n",
    "\n",
    "# Test the model using the test data and print the accuracy\n",
    "accuracy_source = test('MNIST')\n",
    "accuracy_target = test('mnist_m')\n",
    "print(f'Accuracy on source dataset (MNIST): {accuracy_source * 100:.2f}%')\n",
    "print(f'Accuracy on target dataset (mnist_m): {accuracy_target * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
